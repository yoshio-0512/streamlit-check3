import streamlit as st
from PIL import Image, ImageDraw
import numpy as np
import torch
import cv2

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
MODEL_PATH = "e_meter_segadd2.pt"  # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
device = torch.device("cpu")  # å¿…è¦ã«å¿œã˜ã¦ "cuda" ã«å¤‰æ›´

# YOLOv5ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
@st.cache_resource
def load_model(model_path, device):
    model_data = torch.load(model_path, map_location=device)
    model = model_data['model'].float().fuse().eval()  # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«
    return model

model = load_model(MODEL_PATH, device)

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def preprocess_image(image):
    """ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã¦YOLOã®å…¥åŠ›å½¢å¼ã«å¤‰æ›"""
    square_image = expand_image_to_square(image)
    resized_image = square_image.resize((640, 640))
    return np.array(resized_image)

def expand_image_to_square(image, background_color=(255, 255, 255)):
    """ç”»åƒã‚’æ­£æ–¹å½¢ã«å¤‰æ›ã—ã€èƒŒæ™¯ã‚’å¡—ã‚Šã¤ã¶ã™"""
    width, height = image.size
    if width == height:
        return image
    new_size = max(width, height)
    result = Image.new(image.mode, (new_size, new_size), background_color)
    result.paste(image, ((new_size - width) // 2, (new_size - height) // 2))
    return result

def draw_boxes(image, detections):
    """æ¤œå‡ºçµæœã‚’ç”»åƒã«æç”»"""
    draw = ImageDraw.Draw(image)
    for *box, conf, cls in detections:
        x1, y1, x2, y2 = map(int, box)
        draw.rectangle([x1, y1, x2, y2], outline="red", width=3)
        draw.text((x1, y1), f"{cls} {conf:.2f}", fill="red")
    return image

# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
st.title("YOLOv5ã§ã®ç‰©ä½“æ¤œå‡º")
uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["jpg", "jpeg", "png"])
camera_image = st.camera_input("ã¾ãŸã¯ã‚«ãƒ¡ãƒ©ã§ç”»åƒã‚’æ’®å½±ã—ã¦ãã ã•ã„")

if uploaded_file or camera_image:
    # å…¥åŠ›ç”»åƒã‚’Pillowå½¢å¼ã§èª­ã¿è¾¼ã‚€
    input_image = Image.open(uploaded_file or camera_image)
    st.image(input_image, caption="å…¥åŠ›ç”»åƒ", width=300)

    if st.button("ç‰©ä½“æ¤œå‡ºã‚’é–‹å§‹"):
        with st.spinner("ç‰©ä½“ã‚’æ¤œå‡ºä¸­..."):
            try:
                # ç”»åƒã‚’å‰å‡¦ç†
                input_image_cv2 = cv2.cvtColor(np.array(input_image), cv2.COLOR_RGB2BGR)

                # æ¨è«–ã‚’å®Ÿè¡Œ
                results = model(input_image_cv2)

                # æ¤œå‡ºçµæœã®å–å¾—
                detections = results.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2, conf, class]

                if len(detections) == 0:
                    st.error("ç‰©ä½“ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚", icon="ğŸš¨")
                else:
                    # æ¤œå‡ºçµæœã‚’æç”»
                    result_image = draw_boxes(input_image.copy(), detections)
                    st.image(result_image, caption="æ¤œå‡ºçµæœ", width=300)
                    st.download_button("çµæœç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=result_image.tobytes(), file_name="result.png", mime="image/png")

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", icon="âŒ")
